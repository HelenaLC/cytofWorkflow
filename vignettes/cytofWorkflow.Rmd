---
title: "CyTOF workflow"
author: 
  - name: Malgorzata Nowicka
    affiliation: a,b
    email: gosia.nowicka@uzh.ch
  - name: Mark D. Robinson
    affiliation: a,b
address:
  - code: a
    address: Institute for Molecular Life Sciences, University of Zurich, Zurich, 8057, Switzerland
  - code: b
    address: SIB Swiss Institute of Bioinformatics, University of Zurich, Zurich, 8057, Switzerland
abstract: Abstract. 
documentclass: extarticle
fontsize: 10pt
papersize: a4
bibliography: bibliography.bib
output: 
  BiocStyle::html_document:
    fig_caption: true
    self_contained: yes
vignette: >
  %\VignetteIndexEntry{CyTOF workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8} 
---

<!-- To render this document: -->

<!-- rmarkdown::render('cytofWorkflow.Rmd') -->

<!-- knitr::purl('cytofWorkflow.Rmd') -->


```{r setup_knitr, include=FALSE, cache=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = 2, warning = FALSE, message = FALSE, cache.path = "cache/", fig.path = "figure/")
```


# Introduction

<!-- Describe what CyTOF and Flow Cytometry are and what are the differences -->

Flow cytometry and more recently introduced CyTOF (cytometry by time-of-flight mass spectrometry or mass cytometry) are technologies that measure abundance of proteins expressed on the surface or inside cells at the high-throughput single cell level. 
In flow cytometry, antibodies are labeled with fluorescent dyes. For each cell, the intensity of fluorescent parameters is measured using lasers and photodetectors. 
CyTOF utilizes an entirely different technique. Transition element isotopes are used to label antibodies and the intensity read out of isotopes bound to each cell is analyzed with a time-of-flight mass spectrometer. 
In both cases, the intensity of either fluorescent dyes or isotopes is assumed to be proportional to the expression level of antibody-targeted antigens of interest.

Due to the huge differences in these techniques other distinct characteristics are observed.
Classical fluorophore-based flow cytometry is non-destructive and can be also used for cell sorting allowing further analysis on cell populations. Because of the spectral overlap between fluorophores, the compensation analysis has to be performed and a limited number of parameters can be measured at once. A routine experiment measures around 18 parameters with recent increase to up to 50 parameters. On the other hand, flow cytometry offers a high throughput with 10,000 cells measured per second at relatively low operating costs per sample.

By using rare metal isotopes in CyTOF, there is no problem of cell autofluorescence which is a limitation in the classical flow cytometry. As the spectral overlap is greatly reduced, there is little compensation required and a greater number of parameters per cell can be detected. Currently, around 40 parameters can be detected with mass cytometry and theoretically this number could be increased to more than 100 parameters. However, the throughput of CyTOF is lower which is at the rate of hundreds of cells per second and cells can not be collected after an experiment as they are destroyed during the mass spectrometry step.


<!-- Application -->

The ability of flow cytometry and mass cytometry to analyze individual cells at such a high-throughput resulted in a wide range of biological and medical applications. For example, in immunology, they are used to detect and quantify cell populations of interest, to characterize unknown cell populations and to compare population abundance between different conditions, such as different patient groups, resulting in disease biomarker identification.

<!-- Explain what is presented in this workflow -->

There are various methodological approaches available that aim into biomarker discovery [@Saeys2016]. Very common approach [@Hartmann2016] is to first, identify cell populations of interest by the means of manual gating or automated clustering. Second, using some statistical tests, to determine which of the cell subpopulations or protein markers link the sample to a clinical outcome of interest. Typically, cell subpopulation abundance expressed as cluster cell counts or proportions or median marker expression would be used in the statistical model. 
Identification of clusters that are predictive of a phenotypic outcome might be a challenge in this approach as one separates the steps of identifying cell populations and associating them with the phenotypic condition. There can be a situation where a smaller subset of cells is distinct between the conditions, but it can not be detected because it is not annotated as a separate subpopulation. 

Approaches like `Citrus` [@Bruggner2014] tackle this problem by strong over-clustering of the data and building a hierarchy of clusters from very specific to general ones and using a model selection techniques that identify clusters and markers that correlate with the outcome. 
The recently presented `CellCnn` [@Arvaniti2016] learns the representation of clusters that are associated with the considered phenotype by the means of convolutional neural networks, which makes it applicable to detection of rare cell population associations.
s
However, along with the solutions to the problems present in the classic approach new issues arise in the proposed methods. Due to its computational requirements, `Citrus` can not be run on the entire mass cytometry datasets and one has to usually use only a subset of the data. 
`CellCnn` requires a learning step with filters that have to be somehow predefined for each dataset. They do not provide a significance level, such as p-value, for the strength of associations. (DOUBLE CHECK THIS SECTION!!!).

Neither `Citrus` nor `CellCnn` is able to account for more complex designs, such as paired experiment, presence of multiple condition groups or batches, in data.
Strong batch effects which, for example, may result from different runs of mass cytometry, should be handled already at the level of clustering. Since usually all samples are pooled together at this step, strong shifts in marker expression, due to batches, may cause wrong assignment of cells to different populations resulting in the inaccurate abundance measures. With the classic approach, this can be handled by clustering each batch separately and subsequent mapping of cell populations between them. 
Regardless of the clustering strategy, the ability of modeling complex designs in differential analysis is quite relevant and also can be addressed with the classic approach.

All in all, depending on the precise biological question in hand, one has to choose the most suitable approach. Often, it might be that the first classic approach will be satisfying, and by its methodological simplicity, it will bring an ease in the results interpretation. Thus, in this workflow, we preset, step by step, how to proceed with this type of analysis and propose an ensemble of tools and methods that in our opinion provides to the best results.

In this pipeline, cell population identification is conducted by the means of unsupervised cell clustering using the `r Biocpkg("FlowSOM")` and `r Biocpkg("ConsensusClusterPlus")` packages which combined together create one of the best performing clustering approaches [@Weber2016] and does not require subsetting of the data. 

To be able to account for batch effects and paired experiments, we show how to conduct the differential analysis of cell population abundances and marker intensities using the generalized linear mixed models (GLMM) and linear mixed models (LMM), respectively. Model fitting is performed with `r CRANpkg("lme4")` and hypothesis testing with the `r CRANpkg("multcomp")` package.

We use the `r CRANpkg("ggplot2")` package as our graphical engine.
We propose some useful visual representations of the CyTOF data characteristics, such as an MDS plot.
The obtained cell populations are visualized using t-SNE (`r CRANpkg("Rtsne")`) as a dimension reduction technique. The `r CRANpkg("pheatmap")` package is employed to plot heatmaps that represent characteristics of the annotated cell populations and identified biomarkers. 

This workflow is not fully automatic, it involves a step where the user can manually merge and annotate clusters, see Section [Cluster merging and annotation](#cluster-merging-and-annotation), but it is entirely and easily reproducible.
The CyTOF data used here, see Section [Data description](#data-description), is already pre-processed meaning that the normalization and debarcoding as well as removal of doublets, debris and dead cells were already performed. To see how such an analysis could be performed, go to Section [Data preprocessing](#data-preprocessing).
This workflow is equally applicable to any flow cytometry data for which the pre-processing including compensation and the steps listed above were performed.


# Data description

In this workflow, we use a subset of CyTOF data which originates from Bodenmiller et al. [@Bodenmiller2012] and was also used in the `Citrus` paper [@Bruggner2014]. Specifically, we perform our analysis on 16 samples of peripheral blood mononuclear cells (PBMCs) from 8 healthy donors where 8 of them were unstimulated and another 8 were exposed to 30 min BCR/FcR-XL stimulation. For each sample, 14 signaling nodes and 10 cell-surface markers were measured.

The original data can be downloaded from the [Cytobank repository](http://reports.cytobank.org/105/v2). The subset that is used here is available under the [link to Citrus Cytobank repository](https://community.cytobank.org/cytobank/experiments/15713/download_files).

In both, the Bodenmiller et al. and `Citrus` paper, the 10 lineage markers were used to identify PBMCs cell subpopulations which were then investigated for differences in signaling of the 14 functional markers between the reference and stimulated samples. The same strategy is used in this workflow; 10 lineage markers are used for cell clustering and 14 functional markers are tested for the differential expression between the reference and BCR/FcR-XL stimulation. Even though the differential analysis of cell abundance were not in the scope of the Bodenmiller et al. experiment, we present them here for the completeness of this workflow.


# Data preprocessing

TODO: Description of how the pre-processing could be done. Reference to the CATALYST package. Compensation, debarcoding, normalization and removal of debris, doublets and dead cells.


# Data importing

Often the metadata and panel files might be saved as .xls or .xlsx files. There are many ways of loading them into R. You could use the `read.xls` function from the `r CRANpkg("gdata")` package, the `r CRANpkg("data.table")` package (function `fread`),  the `r CRANpkg("xlsx")` package (function `read.xlsx`) or one of the Hadley Wickham packages `r CRANpkg("readr")` or `r CRANpkg("readxl")`. For simple text files, one could use the base `read.table` function.

In our example, we have to define metadata manually. The data frame `md` contains the following columns: 

* `file_name` with names of the .fcs files corresponding to the reference (suffix "Reference") and BCR/FcR-XL stimulation (suffix "BCR-XL") samples that can be seen under the [link to Citrus Cytobank repository](https://community.cytobank.org/cytobank/experiments/15713/download_files),

* `sample_id` with shorter names for each sample containing information about conditions and patient IDs,

* `condition` describes whether samples originate from the reference (`Ref`) or stimulated (`BCRXL`) condition,

* `patient_id` defines the IDs of patients.

The `sample_id` variable is used as row names in metadata and will be used all over the workflow to refer to given samples.
It is very important to carefully check whether variables are of the desired type (factor, numeric, character) as different read-in methods convert columns of the data table into different types. Below, we use `stringsAsFactors = FALSE` meaning that all the character variables will stay characters, otherwise they will be converted into factors. 
We want that the condition variable is a factor with the reference (`Ref`) samples being the reference level, which will be important later for defining models in the differential analysis. The order of factor levels can be defined with the `levels` parameter of the `factor` function.
We also specify colors for the different conditions in a variable `color_conditions`.


```{r load_metadata}
md <- data.frame(file_name = paste0("PBMC8_30min_patient", rep(1:8, each = 2), "_", rep(c("BCR-XL", "Reference"), 8), ".fcs"), sample_id = paste0(rep(c("BCRXL", "Ref"), 8), rep(1:8, each = 2)), condition = rep(c("BCRXL", "Ref"), 8), patient_id = paste0("Patient", rep(1:8, each = 2)), stringsAsFactors = FALSE)

rownames(md) <- md$sample_id

## Make sure condition variables are factors with the right levels
md$condition <- factor(md$condition, levels = c("Ref", "BCRXL"))
head(md)
## Define colors for conditions
color_conditions <- c("#6A3D9A", "#FF7F00")
names(color_conditions) <- levels(md$condition)
```

The .fcs files listed in the metadata can be downloaded manually from the [Citrus Cytobank repository](https://community.cytobank.org/cytobank/experiments/15713/download_files) or automatically from the [Robinson Lab server](http://imlspenticton.uzh.ch/dump/Citrus_paper_data) using the `download.file` function.
The user should make sure that they are placed in the current working directory (`getwd()`) for this workflow to run.

```{r download_fcs}
url <- "http://imlspenticton.uzh.ch/dump/Citrus_paper_data/"
for(i in 1:nrow(md))
download.file(paste0(url, "/", md$file_name[i]), destfile = md$file_name[i])

```

To load the the content of the .fcs files into R, we use the `r Biocpkg("flowCore")` package, and we read in all the files into a `flowSet` object. It is very important to keep in mind that the `read.flowSet` and `read.FCS` functions, by default, may transform the marker intensities and remove cells with extreme positive values. We want to keep this options off to be sure that we have under control the exact amount of data and all the preprocessing steps.

```{r load_fcs, include=FALSE}
library(flowCore)

file_names <- md$file_name
fcs_raw <- read.flowSet(file_names, transformation = FALSE, truncate_max_range = FALSE)
```

```{r load_fcs2, eval = FALSE}
library(flowCore)

file_names <- md$file_name
fcs_raw <- read.flowSet(file_names, transformation = FALSE, truncate_max_range = FALSE)
```

```{r load_fcs3}
fcs_raw
```

The panel information can be available in two ways: as an additional text file which typically contains a column with the .fcs file names, the `Isotope` and `Metal` variables defining the atomic mass number and the symbol of the chemical element conjugated to the antibody in the mass cytometry, `Antigen` which specifies the protein marker that was targeted and some other columns specific to the experiment.

The isotope, metal and antigen information is also stored in the `flowSet` or `flowFrame` objects. You can type in R `fcs_raw[[1]]`, you will see a table with columns `name` and `desc`. Their content can be accessed with functions `pData(parameters())` and is identical for all the `flowFrame` objects in the `flowSet`. The variable `name` corresponds to the column names in the `flowSet` object, you can type in R `colnames(fcs_raw)`.

Typically, you want to make sure that the channels in panel are ordered in the same way as in the `flowSet` object to make your analysis less prone to subsetting mistakes.
We create a data frame called `panel` with `name` and `desc` columns and an information whether a given channel corresponds to a lineage or a functional marker that we want to use in the following analysis. 

```{r load_panel}
panel <- data.frame(pData(parameters(fcs_raw[[1]]))[, c("name", "desc")], stringsAsFactors = FALSE)

lineage_markers <- c("CD45", "CD4", "CD20", "CD33", "CD123", "CD14", "IgM", "HLA-DR", "CD7", "CD3")
functional_markers <- c("pNFkB", "pp38", "pStat5", "pAkt", "pStat1", "pSHP2", "pZap70", "pStat3", "pSlp76", "pBtk", "pPlcg2", "pErk", "pLat", "pS6")

panel$lineage_marker <- panel$desc %in% lineage_markers
panel$functional_marker <- panel$desc %in% functional_markers
head(panel)
```


# Data transformation

In the following analysis, we want to include only those channels that correspond to the lineage and functional markers. It is a common practice to transform marker intensities using, for example, arcsineh (hyperbolic inverse sine) with cofactor 5 [@Bendall687 Figure S2, @Bruggner2014]. We also rename the columns in the `flowSet` to the antigen names from `panel$desc`.

```{r arcsinh_transformation}
## Arcsineh transformation
fcs <- fsApply(fcs_raw, function(x){
  colnames(x) <- panel$desc
  expr <- exprs(x)
  expr <- asinh(expr[, c(lineage_markers, functional_markers)] / 5)
  exprs(x) <- expr
  return(x)
})
```


For some of the further analysis, it is more convenient for us to work using a matrix (called `expr`) that contains marker expression for cells from all the samples. We create such a matrix with the `fsApply` function which we use to extract the expression matrices (function `exprs`) from each element of the `flowSet` object. 


```{r extract_expression}
## Extract expression
expr <- fsApply(fcs, exprs)
```

As the ranges of marker intensities can vary substantially, we apply another transformation that scales expression of all markers to values between 0 and 1. Such transformed data, which is used for plotting heatmaps, gives better representation of relative differences in marker expression between annotated cell populations.

```{r 01_transformation}
rng <- apply(expr, 2, quantile, p = c(0.01, 0.99))
expr01 <- t((t(expr) - rng[1, ]) / (rng[2, ] - rng[1, ]))
expr01[expr01 < 0] <- 0
expr01[expr01 > 1] <- 1
```


# Spot-check plots

In this Section, we propose some quick checks to verify whether the data we analyze globally represents what we expect. For instance, whether samples that are supposed to be replicates of one condition group together and are distinct from samples from another conditions.  

One of the important checks is to verify whether marker expression distributions do not have any abnormalities, such as, extremely large or low range of expression or a very distinct distribution pattern for only a part of the samples from a condition. This could indicate some problems with the mass cytometry experiment for some markers or some batch effects that were originally not expected. One can then consider removing such problematics markers and samples from the further analysis.

In this workflow, we generate all the plots, except heatmaps, with the `r CRANpkg("ggplot2")` engine. 
The code chunk below, generates a plot with per sample marker expression distributions colored by condition.

(INTERPRETATION?)

```{r sample_ids}
## Generate sample IDs corresponding to each cell in the `expr` matrix
sample_ids <- rep(md$sample_id, fsApply(fcs_raw, nrow))
```


```{r plot_merker_expression_distribution, fig.cap = "One of the spot-check plots representing the per sample marker expression distributions. Samples are colored according to the condition they belong to."}
library(ggplot2)
library(reshape2)

ggdf <- data.frame(sample_id = sample_ids, expr)
ggdf <- melt(ggdf, id.var = "sample_id", value.name = "expression", variable.name = "antigen")
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- md$condition[mm]

ggplot(ggdf, aes(x = expression, color = condition, group = sample_id)) +
  geom_density() +
  facet_wrap(~ antigen, nrow = 4, scales = "free") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(color = guide_legend(ncol = 1)) +
  scale_color_manual(values = color_conditions)

```

Another spot-chek is the number of cells per sample.

(INTERPRETATION?)

```{r plot_number_of_cells, fig.cap = "Barplot with the number of cells per sample."}
cell_table <- table(sample_ids)

ggdf <- data.frame(sample_id = names(cell_table), cell_counts = as.numeric(cell_table))
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- md$condition[mm]

ggplot(ggdf, aes(x = sample_id, y = cell_counts, fill = condition)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = cell_counts), hjust=0.5, vjust=-0.5, size = 3) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), legend.position = "none") +
  scale_fill_manual(values = color_conditions, drop = FALSE) +
  scale_x_discrete(drop = FALSE)

```


## MDS plot

In genomics, one of the most important exploratory plots is the multi-dimensional scaling (MDS) plot or a principal component analysis (PCA) plot. Both of them show similarities and dissimilarities between samples measured in an unsupervised way and give an idea on how much differential expression can be detected before conducting any formal tests.
An MDS plot can be generated with the `plotMDS` function from the `r Biocpkg("limma")` package. In genomics, distances between samples are calculated based on the expression of the top varying genes. 
We propose to generate a similar plot for CyTOF data, where, for example, median marker expression is used to calculate dissimilarities between samples. 

Ideally, samples should cluster well within the same condition. If this is not the case, one can identify the outlier samples and eliminate them, for example, if there are enough samples left for the further analysis. Otherwise, one has to keep in mind that such samples will be a source of error and extra variation.

In out MDS plot, we can see that the first dimension MDS1 separates very well the reference and stimulated samples. The second dimension MDS2 represents the differences between patients. Most of the samples that originate from the same patients are placed at a similar point along the y-axis, for example, samples from patients 7, 5, and 8  are on the top of the plot, samples from patient 4 are located at the bottom of the plot. This indicates that the within patient variability is relatively small, and one should consider account for it in the differential model as it is often the case in paired experiments.


```{r plot_mds, fig.cap = "MDS plot based on the median marker expression."}
# Get the median marker expression per sample
expr_median_sample <- aggregate(expr, by = list(sample_id = sample_ids), FUN = median)
rownames(expr_median_sample) <- expr_median_sample[, 1]
expr_median_sample <- t(expr_median_sample[, -1])

library(limma)
mds <- plotMDS(expr_median_sample, plot = FALSE)

library(ggrepel)
ggdf <- data.frame(MDS1 = mds$x, MDS2 = mds$y, sample_id = colnames(expr_median_sample))
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- md$condition[mm]

ggplot(ggdf, aes(x = MDS1, y = MDS2, color = condition)) +
  geom_point(size = 2, alpha = 0.8) +
  geom_label_repel(aes(label = sample_id)) +
  theme_bw() +
  scale_color_manual(values = color_conditions) 

```

In contrast to genomic applications, the number of variables measured for each sample is much lower in mass or flow cytometry. In the former there are thousands of genes sequenced, and in the latter between 20 and 100 antigens are targeted. 
We find that a plot proposed below gives also a good insight into the structure of the data. It is a heatmap of median marker intensities with clustered columns (samples) and rows (markers). 
We have used hierarchical clustering with average linkage and euclidean distance, but also Ward's linkage could be used [@Bruggner2014], and in CyTOF applications, a cosine distance shows good performance [@Bendall2014].
Its interpretation is similar as of the MDS plot. Samples from within condition should cluster together. Additionally, in this plot, we can see which markers drive the observed clustering of samples.

We can see in this plot, that the dendrogram separates very well the reference and stimulated samples. Also the very strong consistency in similarity between patients can be observed, for example, patients 1 and 2 or patients 6, 7 and 8 or 3 and 4 are more similar to each other in both conditions.

```{r plot_dendogram, fig.cap = "Clustering of samples and markers based on the median marker expression."}
library(RColorBrewer)
library(pheatmap)

# Cluster samples
d <- dist(t(expr_median_sample), method = "euclidean")
cluster_cols <- hclust(d, method = "average")
# Cluster markers
d <- dist(expr_median_sample, method = "euclidean")
cluster_rows <- hclust(d, method = "average")

# Column annotation for the heatmap
mm <- match(colnames(expr_median_sample), md$sample_id)
annotation_col <- data.frame(condition = md$condition[mm])
rownames(annotation_col) <- colnames(expr_median_sample)
annotation_colors <- list(condition = color_conditions)
# Colors for the heatmap
color <- colorRampPalette(brewer.pal(n = 9, name = "YlGnBu"))(100)

pheatmap(expr_median_sample, color = color, cluster_cols = cluster_cols, cluster_rows = cluster_rows, display_numbers = TRUE, number_color = "black", fontsize_number = 5, annotation_col = annotation_col, annotation_colors = annotation_colors)

```


# Marker ranking based on the non-redundancy score

In this step, we identify the ability of markers to stratify cells into different subpopulations in each sample. For that, we calculate the non-redundancy score (NRS) [@Levine2015] which is based on the PCA analysis.
Markers with higher score explain larger portion of variability that is present in a given sample. 

The average NRS can be used to select a subset of markers which are non-redundant in each sample but at the same time capture the overall diversity between samples. Such a subset of markers can be then used for the cell population identification analysis that follow next. 
There is no precise rule on how to choose the right cutoff for marker inclusion, but one of the approaches is to select just some number of the top-scoring markers. The number can be chosen by analyzing the plot with the NR scores, shown below, where the markers are sorted by the decreasing average NRS. One can drop out markers that are not likely to distinguish cell populations of interest, even if they have high scores, and add in markers with low scores but known to be important in discerning cell subgroups.

In the analysis of the dataset that is considered here, there is no need for shrinking of the subset of cell-surface marker which will be used for cell population identification. We want to use all the 10 linkage markers. However, there can be studies were such preselection might be of interest.

```{r nrs, fig.cap = "Non-redundancy scores. Colorful points represent the per sample NR scores, while white points indicate the mean NR scores from all the samples. Markers on the x-axis are sorted according to the decreasing average NRS."}
## Define a function that calculates the NRS per sample 
NRS <- function(x, ncomp = 3){
  pr <- prcomp(x, center = TRUE, scale. = FALSE) 
  score <- rowSums(outer(rep(1, ncol(x)), pr$sdev[1:ncomp]^2) * abs(pr$rotation[,1:ncomp]))
  return(score)
}

## Calculate the score
nrs_sample <- fsApply(fcs[, lineage_markers], NRS, use.exprs = TRUE)
rownames(nrs_sample) <- md$sample_id
nrs <- colMeans(nrs_sample, na.rm = TRUE)

## Plot the NRS for ordered markers
lineage_markers_ord <- names(sort(nrs, decreasing = TRUE))
nrs_sample <- data.frame(nrs_sample, check.names = FALSE)
nrs_sample$sample_id <- rownames(nrs_sample)

ggdf <- melt(nrs_sample, id.var = "sample_id", value.name = "nrs", variable.name = "antigen")

ggdf$antigen <- factor(ggdf$antigen, levels = lineage_markers_ord)
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- md$condition[mm]

ggplot(ggdf, aes(x = antigen, y = nrs)) +
geom_point(aes(color = condition), alpha = 0.9, position = position_jitter(width = 0.3, height = 0)) +
  geom_boxplot(outlier.size = NA, fill = NA) +
  stat_summary(fun.y = "mean", geom = "point", shape = 21, fill = "white") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  scale_color_manual(values = color_conditions)
```


# Cell population identification with FlowSOM and ConsensusClusterPlus

Cell population identification often has been carried out by manual gating a method based on visual inspection of two-dimensional scatterplots, where at each step a subset of cells, which is positive or negative for the given two markers, is selected and further stratified in the next iteration until a population with given marker characteristics is selected. Despite its popularity, manual gating has many drawbacks such as subjectivity, bias toward the favorite cell types, high time workload and inefficiency when analyzing large datasets, which all contribute to the fact that manual gating is hard to reproduce [@Saeys2016].
Large effort has been carried out to improve and automate cell population identification and many methods are currently available that address this question by the means of unsupervised clustering of cells [@Weber2016]. 

In this workflow, we conduct cell clustering with the suite of packages `r Biocpkg("FlowSOM")` [@VanGassen2015] and `r Biocpkg("ConsensusClusterPlus")` [@Wilkerson2010] that was concluded to be one of the best performing clustering approaches currently available [@Weber2016]. This ensemble has a very good capability of detecting both main and smaller cell populations and is one of the fastest methods to run, which enables its usage in the interactive analysis.
We use a slight modification of the original workflow presented in the `r Biocpkg("FlowSOM")` vignette, which we find  more flexible.
Namely, we directly call the `ConsensusClusterPlus` function which is embedded in `metaClustering_consensus`. Thanks to that, we are able to access all the functionality of the `r Biocpkg("ConsensusClusterPlus")` package, which is helpful in the cluster number identification.

The `r Biocpkg("FlowSOM")` workflow consists of tree main statistical steps. Building the self-organizing map (SOM) with the `BuildSOM` function which is a working horse for clustering where cells are assigned according to their similarities to 100 grid points (codes) of the SOM. Building of the minimal spanning tree (MST), which is mainly used for graphical representation of clusters and is skipped in this pipeline. And finally, metaclustering of the SOM codes, which we prefer to perform directly with the `ConsensusClusterPlus` function. Additionally, we continue with the second round of merging of the metaclusters in a semi automatic fashion.

`r Biocpkg("FlowSOM")` output is sensitive to random starts. To be sure that results are reproducible one must specify the seed for the random number generation in R using function `set.seed`. It is also advisable to rerun analyses with multiple random seeds for two reasons. To see how robust are the detected clusters, and when the goal is to find smaller cell populations, it may happen that in some runs, random starting points do not represent rare cell populations as a chance of selecting starting cells from them is low and they are merged into a larger cluster.

It is important to point out that, we cluster cells from all the samples together. This strategy is beneficial, as we have to label cell populations only once, and  the mapping of cell types between samples is automatically consistent. However, this approach works only if the variability between samples is small enough. 

In case of batches, for example, samples were measured with two different runs of CyTOF and clear differences between these time points can be observed in the spot-check plots (Section [Spot-check plots](#spot-check-plots)), one should consider separate clustering of samples from these batches. Clustering them together may result in an inaccurate cell assignment to different populations and might lead to artifacts in the following analysis, such as differential abundance analysis. However, to be able to use results from separate clustering analysis, for example, in the differential analysis, one has to make sure that the mapping of cell populations between them is accurate by, for example, using the same cluster names. And of course, the batch information should be included in the differential model.

In our analysis, cell populations are identified using only the 10 lineage markers which we define in the `BuildSOM` function with the `colsToUse` argument.

```{r flowsom_som}
library(FlowSOM)

fsom <- ReadInput(fcs, transform = FALSE, scale = FALSE)
set.seed(1234)
som <- BuildSOM(fsom, colsToUse = lineage_markers)
```

Often automatic approaches for selecting the number of clusters present in the data do not work very well [@Weber2016]. It is recommended to over-cluster, and if necessary, perform manual merging of clusters during the downstream analysis. Such hierarchical approach is especially suited when the goal is to detect smaller cell populations.

The SPADE analysis performed by Bodenmiller et al. [@Bodenmiller2012] identified 6 main cell types (T-cells, monocytes, dendritic cells, B-cells, NK cells, surface- cells) which were further stratified into 14 more specific subpopulations (CD4+ T-cells, CD8+ T-cells, CD14+ HLADR+ monocytes, CD14+ HLADR- monocytes, CD14- HLADR+ monocytes, CD14- HLADR- monocytes, dendritic cells, IgM+ B-cells, IgM- B-cells, NK cells, surface- CD14+ cells and surface- CD14- cells). 
In our analysis, we are interested in identifying similar cell populations. Thus, we perform the metaclustering of the 100 SOM codes into more than 14 groups, hopefully stratification into 30 groups will give enough resolution. 
We will verify that with t-SNE plots, heatmaps and one of the plots generated by `ConsensusClusterPlus` called delta area, and all of them will be described later in this workflow.

We call the `ConsensusClusterPlus` with maximum number of clusters `maxK = 30` and other clustering parameters set to the values as in the `metaClustering_consensus` function. Again, to ensure that the analysis are reproducible, we define the random seed with parameter `seed`.


```{r flowsom_meta_clustering, message = FALSE}
## Metaclustering into 20 clusters with ConsensusClusterPlus
library(ConsensusClusterPlus)

codes <- som$map$codes
plot_outdir <- "consensus_plots"
nmc <- 30

mc <- ConsensusClusterPlus(t(codes), maxK = nmc, reps = 100, pItem = 0.9, pFeature = 1, title = plot_outdir, plot = "png", clusterAlg = "hc", innerLinkage = "average", finalLinkage = "average", distance = "euclidean", seed = 1234)

## Get cluster ids for each cell
code_clustering <- mc[[nmc]]$consensusClass
cell_clustering <- code_clustering[som$map$mapping[,1]]
```

We can investigate characteristics of identified clusters with heatmaps which illustrate median marker expression in each cluster. 
As the range of marker expression can vary quite substantially from marker to marker, we use the data that is transformed to the common range between 0 and 1, which can make the relative comparison between markers easier. However, to stay consistent with `FlowSOM` and `ConsensusClusterPlus`, we use the unscaled data to generate the dendrogram of the hierarchical structure of metaclusters.

Instead of using only medians, which do not give a full representation of cluster specifics, one can plot an entire marker expression distribution in each cluster. Such a plot gives more detailed profile of each cluster. However, we find that it is harder to analyze such a plot. Heatmaps give the overall overview of clusters, are quicker and easier to interpret and together with the dendrogram can be a good basis for further cluster merging, see Section [Cluster merging and annotation](#cluster-merging-and-annotation).

Since we will use the heatmap and density plots again later in this workflow, in code chunks below, we create wrapper functions that generate these two types of plots.


```{r color_clusters}
color_clusters <- c("#DC050C", "#FB8072", "#1965B0", "#7BAFDE", "#882E72", "#B17BA6", "#FF7F00", "#FDB462", "#E7298A", "#E78AC3", "#33A02C", "#B2DF8A", "#55A1B1", "#8DD3C7", "#A6761D", "#E6AB02", "#7570B3", "#BEAED4", "#666666", "#999999", "#aa8282", "#d4b7b7", "#8600bf", "#ba5ce3", "#808000", "#aeae5c", "#1e90ff", "#00bfff", "#56ff0d", "#ffff00")

```


```{r plot_clustering_heatmap, fig.cap = "Heatmap of the median marker intensities in 30 cell populations obtained from the metaclustering step. The dendrogram on the left represents the hierarchical similarity between the metaclusters."}

plot_clustering_heatmap_wrapper <- function(expr, expr01, cell_clustering, color_clusters, cluster_merging = NULL){
  
  # Get the median expression
  expr_median <- aggregate(expr, by = list(cell_clustering = cell_clustering), FUN = median)
  expr01_median <- aggregate(expr01, by = list(cell_clustering = cell_clustering), FUN = median)
  
  # Get cluster frequencies
  clustering_table <- as.numeric(table(cell_clustering))
  
  # This clustering is based on the markers that were used for the main clustering
  d <- dist(expr_median[, colnames(expr)], method = "euclidean")
  cluster_rows <- hclust(d, method = "average")
  
  expr_heat <- as.matrix(expr01_median[, colnames(expr01)])
  rownames(expr_heat) <- expr01_median$cell_clustering
  
  labels_row <- paste0(rownames(expr_heat), " (", round(clustering_table / sum(clustering_table) * 100, 2), "%)")
  labels_col <- colnames(expr_heat)
  
  # Row annotation for the heatmap
  if(is.null(cluster_merging)){
    annotation_row <- data.frame(cluster = factor(expr01_median$cell_clustering))
    rownames(annotation_row) <- rownames(expr_heat)
  }else{
    annotation_row <- data.frame(cluster = cluster_merging$new_cluster)
    rownames(annotation_row) <- rownames(expr_heat)
  }
  
  names(color_clusters) <- levels(annotation_row$cluster)
  annotation_colors <- list(cluster = color_clusters)
  
  # Colors for the heatmap
  color <- colorRampPalette(rev(brewer.pal(n = 9, name = "RdYlBu")))(100)
  
  pheatmap(expr_heat, color = color, cluster_cols = FALSE, cluster_rows = cluster_rows, labels_col = labels_col, labels_row = labels_row, display_numbers = TRUE, number_color = "black", fontsize = 8, fontsize_number = 4, annotation_row = annotation_row, annotation_colors = annotation_colors)
  
}

plot_clustering_heatmap_wrapper(expr = expr[, lineage_markers_ord], expr01 = expr01[, lineage_markers_ord], cell_clustering, color_clusters)

```



```{r plot_clustering_distribution, fig.cap = "Distributions of marker intensities in 30 cell populations obtained from the metaclustering step. Blue densities represent marker expression for cells in given clusters. Grey densities are calculated from all the cells and serve as a reference."}
plot_clustering_distr_wrapper <- function(expr, cell_clustering){
  
  cell_clustering <- factor(cell_clustering)
  expr_median <- aggregate(expr, by = list(cell_clustering), FUN = median)
  d <- dist(expr_median[, colnames(expr)], method = "euclidean")
  cluster_rows <- hclust(d, method = "average")
  cell_clustering <- factor(cell_clustering, levels = levels(cell_clustering)[cluster_rows$order])
  
  freq_clust <- table(cell_clustering)
  freq_clust <- round(as.numeric(freq_clust)/sum(freq_clust)*100, 2)
  cell_clustering <- factor(cell_clustering, labels = paste0(levels(cell_clustering), " (", freq_clust, "%)"))
  
  ggd <- melt(data.frame(cluster = cell_clustering, expr, check.names = FALSE), id.vars = "cluster", value.name = "expression", variable.name = "antigen")
  ggd$antigen <- factor(ggd$antigen, levels = colnames(expr))
  
  ggplot(data = ggd, aes(x = expression, y = ..scaled..)) +
    geom_density(data = transform(ggd, cluster = NULL), color = "darkgrey", fill = "black", adjust = 1, alpha = 0.3) +
    geom_density(color = "blue", fill = "blue", adjust = 1, alpha = 0.3) +
    facet_grid(cluster ~ antigen, scales = "free") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1), axis.text = element_text(size = 5), strip.text = element_text(size = 5)) 
  
}

plot_clustering_distr_wrapper(expr = expr[, lineage_markers_ord], cell_clustering)

```


## Visual representation with t-SNE

One of the most popular plots that are used to represent cell populations, are the t-SNE plots, where each cell is represented in a new lower, usually two-dimensional, space which was computed using the  t-stochastic neighbor embedding (t-SNE) [@VanDerMaaten2008]. The new dimensions are supposed to capture the similarity between cells from the original dimensions. This method has been shown to work very well with flow and mass cytometry data. 

Nevertheless, there are few things to be cautious about. Because it is based on preserving similarities between cells, cells that are similar in the original space will be close in the 2D representation, but the opposite does not always hold. Thus, one has to be careful with the interpretation of t-SNE plots. For more guidance see [How to Use t-SNE Effectively](http://distill.pub/2016/misread-tsne/).

Due to the stochastic nature of t-SNE, rerunning the method can result in different 2D representation of cells. It is advisable to run it few times to identify the common trends and and get feeling about the variability of the results.
To be sure that the analysis are reproducible, the user has to define the random seed before running the method.

t-SNE is a method that requires some substantial computational time to process the data for even few tens of thousands of cells. CyTOF datasets are usually much larger. To keep the running time reasonable one can use only a subset of cells for this particular graphical representation, for example, 2000 cells from each sample. 

The t-SNE map below is colored according to the expression level of the CD4 marker showing that the CD4+ cells are placed to the left side of the plot. One can use other markers to get an idea where which types of cells are located on this map.


```{r tsne_duplicates_subsampling}
## Find and skip duplicates
dups <- which(!duplicated(expr[, lineage_markers]))

## Data subsampling
## Create indices by sample
inds <- split(1:length(sample_ids), sample_ids) 

## How many cells to downsample per-sample
tsne_ncells <- pmin(table(sample_ids), 2000)  

## Get subsampled indices
set.seed(1234)
tsne_inds <- lapply(names(inds), function(i){
  s <- sample(inds[[i]], tsne_ncells[i], replace = FALSE)
  intersect(s, dups)
})

tsne_inds <- unlist(tsne_inds)

tsne_expr <- expr[tsne_inds, lineage_markers]
```

```{r tsne_run}
## Run t-SNE
library(Rtsne)

set.seed(1234)
tsne_out <- Rtsne(tsne_expr, check_duplicates = FALSE, pca = FALSE)

```


```{r tsne_plot_one_expr_CD4, fig.cap = "t-SNE plot with cells colored according to the expression level of the CD4 marker."}
## Plot t-SNE colored by CD4 expression
dr <- data.frame(tSNE1 = tsne_out$Y[, 1], tSNE2 = tsne_out$Y[, 2], expr[tsne_inds, lineage_markers])

ggplot(dr,  aes(x = tSNE1, y = tSNE2, color = CD4)) +
  geom_point() +
  theme_bw() +
  scale_color_gradientn("CD4", colours = colorRampPalette(rev(brewer.pal(n = 11, name = "Spectral")))(100))

```


We can color the cells by the cluster they belong to. Ideally, cells of the same color should be close to each other. When the figure is stratified per sample, we can verify whether similar cell populations are present in the condition replicates which is another mean to identify any outlying samples. 


```{r tsne_plot_one, fig.cap = "t-SNE plot with cells colored according to the 30 metaclusters."}
dr$sample_id <- sample_ids[tsne_inds]
dr$cell_clustering <- factor(cell_clustering[tsne_inds], levels = 1:nmc)

## Plot t-SNE colored by clusters
ggp <- ggplot(dr,  aes(x = tSNE1, y = tSNE2, color = cell_clustering)) +
  geom_point() +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))
ggp
```

```{r tsne_plot_facet_sample, fig.cap = "t-SNE plot stratified by sample."}
## Facet per sample
ggp + 
facet_wrap(~ sample_id) 
```


The SOM codes represent characteristics of the 100 clusters generated in the first step of the `FlowSOM` pipeline. Their visualization can be also helpful in understanding the cell population structure and determining the number of clusters. In the end, the metaclustering step uses them and not the original cells.
We treat the codes as new representative cells and apply the t-SNE dimension reduction to be able to plot them in 2D. The size of the points corresponds to the number of cells that were assigned to a given code. The points are colored according to the results of metaclustering. 
Since we have only 100 data points, the t-SNE analysis are very quick.

As t-SNE plots can sometimes be tricky to interpret, it is always a good practice to try to visualize data with other methods to see how consistent are the observed patterns. For example, we represent the codes also in the PCA dimensions. 


```{r som_codes_size}
## Get code sizes; sometimes not all the codes have mapped cells so they will have size 0
code_sizes <- table(factor(som$map$mapping[, 1], levels = 1:nrow(codes))) 
code_sizes <- as.numeric(code_sizes)

```

```{r som_codes_dimension_reduction}
## Run t-SNE on codes
set.seed(1234)
tsne_out <- Rtsne(codes, pca = FALSE)
## Run PCA on codes
pca_out <- prcomp(codes, center = TRUE, scale. = FALSE)
```


```{r plot_som_codes_tsne, fig.cap = "t-SNE plot representing the SOM codes colored according to the metaclustering into 30 cell populations."}
codes_dr <- data.frame(tSNE1 = tsne_out$Y[, 1], tSNE2 = tsne_out$Y[, 2], PCA1 = pca_out$x[, 1], PCA2 = pca_out$x[, 2])
codes_dr$code_clustering <- factor(code_clustering)
codes_dr$size <- code_sizes

## Plot t-SNE on codes
ggplot(codes_dr,  aes(x = tSNE1, y = tSNE2, color = code_clustering, size = size)) +
  geom_point(alpha = 0.9) +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))

```


```{r plot_som_codes_pca, fig.cap = "PCA plot representing the SOM codes colored according to the metaclustering into 30 cell populations."}
## Plot PCA on codes
ggplot(codes_dr,  aes(x = PCA1, y = PCA2, color = code_clustering, size = size)) +
  geom_point(alpha = 0.9) +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))

```


## Cluster merging and annotation

When a clustering analysis is started with an expectation of identifying some number k of specific clusters, it is quite uncommon that `FlowSOM`, or any other methods, can identify them when the desired number of clusters is set to exactly k. Over-clustering is necessary for two reasons, so the smaller populations could be separated from the main populations and so the unexpected clusters could be detected.
If the over-clustering is too strong, one can merge back the clusters that should represent larger cell populations.

In our setup, over-clustering is also useful when the interest is in identifying the "natural" number of clusters present in the data. Additionally to the t-SNE plots, one could investigate the the delta area plot from the `ConsensusClusterPlus` package and the hierarchical clustering dendrogram of the over-clustered subpopulations, see the following Sections.


In out example, we are interested in detecting 14 specific cell types, and we have performed clustering into 30 groups.
After analyzing the heatmaps and t-SNE plots, we can clearly see that stratification of the data into 30 clusters may be too strong. 
Many clusters are placed very close to each other indicating that they could be merged together. The same can be deduced from the heatmaps; marker expression patterns for some of the clusters are very similar. 

Cluster merging and annotating is somewhat a manual step, based on parallel investigation of t-SNE plots and heatmaps, but we will show how it could be, at least partially, simplified and if need automated.


### Reducing the number of clusters in ConsensusClusterPlus

The `ConsensusClusterPlus` package provides some visualizations that can help understanding the metaclustering process and the characteristics of the analyzed data. One of the plots represents, so called, delta area, which can be interpreted as a score for each possible number of clusters from k=2 to k=30. For a given k, it indicates the amount of extra cluster stability gained when clustering into k groups as compared to k-1 groups. 
It can be expected that high stability of clusters can be reached when clustering into the number of groups that best fits the data. 
Thus, this score could be used as a method for finding the "natural" number of clusters present in the data, which corresponds to k at which there is no appreciable increase in stability. This strategy can be referred as the  "elbow criterion". For more details about the meaning of this plot, the user can refer to the original description of the consensus clustering method [@Monti2003].

The elbow criterion is quite a subjective method since the "appreciable" increase is not defined exactly. For example, in the delta plot below, we could say that the last point before plato is for k=6, or for k=5, or for k=3. Moreover, the "exact" point where plato is reached may vary for runs with different random seeds, the drop may not always be so sharp and the function may not always be so nicely decreasing.
It is advised to investigate more of those plots and the resulting t-SNE and heatmaps before drawing any conclusions about the final number of "natural" clusters. 

In our use case, we are interested in defining the 14 clusters of interest. 
Manual merging of as many as 30 clusters can be sometimes problematic.
To simplify this task, one could reduce the strength of over-clustering and allow the metaclustering method to do some part of the merging. Analyzing the delta plot from the right side, we can see how much we can reduce the over-clustering while still obtaining stable clusters. In parallel, one should check the heatmaps to see whether the less stringent stratification is able to capture cell populations of interest.


![The delta area plot from ConsensusClusterPlus indicating the relative increase in cluster stability obtained when clustering into k groups.](consensus_plots/consensus032.png)


```{r flowsom_meta_clustering2}
## Get cluster ids for each cell
nmc2 <- 6
code_clustering2 <- mc[[nmc2]]$consensusClass
cell_clustering2 <- code_clustering2[som$map$mapping[, 1]]
```


```{r plot_som_codes2}
## Plot new clustering2
codes_dr$code_clustering2 <- factor(code_clustering2)

ggplot(codes_dr,  aes(x = tSNE1, y = tSNE2, color = code_clustering2, size = size)) +
  geom_point(alpha = 0.9) +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))

```


```{r tsne_plot_one_clustering2}
dr$cell_clustering2 <- factor(cell_clustering2[tsne_inds], levels = 1:nmc2)
ggplot(dr,  aes(x = tSNE1, y = tSNE2, color = cell_clustering2)) +
  geom_point() +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))
```


```{r plot_heatmap2}
plot_clustering_heatmap_wrapper(expr = expr[, lineage_markers_ord], expr01 = expr01[, lineage_markers_ord], cell_clustering = cell_clustering2, color_clusters = color_clusters[1:nmc2])
```


### Manual cluster merging and annotating based on heatmaps

Cluster merging based on t-SNE maps only may lead to some artificial results as the accurate interpretation of t-SNE plots is sometimes difficult. Clusters that are relatively close in the 2D representation can in fact be quite distant in the original space and the relative position can be rotated. The clear boundaries between cell groups may be not well visible and usually only a subset of cells is presented.

We think, it is better to use as a main reference heatmaps of marker characteristics in each metacluster together with dendrograms showing the similarity hierarchy among them. Of course, this plots are not ideal either because they aggregate information over many cells showing an average picture of each cluster but combined with t-SNE give a good insight into the data structure.
It is important to keep in mind that the engines of these methods are very different. Thus, in the data where clusters are very distinct, their concordance will be very high, but in the data where the separations are not so obvious, they may highlight different cell populations, which usually are not wrong, they are just different. It is then left to the researcher to decide which of the cell clusters are more meaningful to the conducted study.

From the dendrogram, we can see what is the similarity structure between the metaclusters. Investigated from the bottom (leaves) to the top (root) shows in which order clusters could be merged together.
However, we find few reasons for which one not always have to strictly follow a given dendrogram merging. 
As in general when it comes to clustering, this strategy will lead to identification of populations of similar cells, but it does not necessarily mean that they are of our interest. 
The distances between metaclusters are calculated over all the markers. It may be that in some instances grouping together clusters based on similar expression of one or two markers makes more biological sense, even if they are on the opposite sides of the dendrogram. 
On top, different linkage methods may lead to different hierarchy, especially when clusters are not highly distinct, which again is not wrong, it is just focused on different characteristics of clusters.

A very important aspect to consider in cluster merging it the cluster size represented in the parentheses next to the cluster label. If the cluster size is very small, but the cluster seems relevant, one can keep it as separate or merge it with the nearest larger cluster. If it looks as an outlier, one could eliminate it from the further analysis.

In case an automated solution for cluster merging is needed, one could use the `cutree()` function.

The cluster merging is defined in the `cluster_merging` data frame with the IDs of the original clusters and new cluster names.

```{r cluster_merging}
cluster_merging <- data.frame(original_cluster = 1:30, new_cluster = factor(paste0("cl", 1:30), levels = paste0("cl", 1:30)))
cluster_merging

## New clustering3
mm <- match(cell_clustering, cluster_merging$original_cluster)
cell_clustering3 <- cluster_merging$new_cluster[mm]

mm <- match(code_clustering, cluster_merging$original_cluster)
code_clustering3 <- cluster_merging$new_cluster[mm]
```


```{r plot_som_codes3}
## Plot new clustering3
codes_dr$code_clustering3 <- factor(code_clustering3)

ggplot(codes_dr,  aes(x = tSNE1, y = tSNE2, color = code_clustering3, size = size)) +
  geom_point(alpha = 0.9) +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))
```


```{r tsne_plot_one_clustering3}
dr$cell_clustering3 <- factor(cell_clustering3[tsne_inds])
ggplot(dr,  aes(x = tSNE1, y = tSNE2, color = cell_clustering3)) +
  geom_point() +
  theme_bw() +
  scale_color_manual(values = color_clusters) +
  guides(color = guide_legend(override.aes = list(size = 4), ncol = 2))
```


```{r plot_heatmap3, fig.cap='Heatmap for clustering3.'}
plot_clustering_heatmap_wrapper(expr = expr[, lineage_markers_ord], expr01 = expr01[, lineage_markers_ord], cell_clustering = cell_clustering, color_clusters = color_clusters[1:nlevels(cell_clustering3)], cluster_merging = cluster_merging)

```



# Differential analysis 

For the dataset used in this workflow, the main goal is to identify subsets of PBMCs that responded to BCR/FcR-XL stimulation compared with PBMCs without treatment, which corresponds to the differential expression analysis of 14 signaling markers stratified by cell population conducted in the following Section. 
Additionally, we present how to perform differential abundance analysis and differential analysis of the overall maker expression, as they might be a goal in many other studies based on CyTOF data.

The PBMC subset analyzed in this workflow originates from a paired experiment, where samples from 8 patients were treated with 12 different stimulation conditions for 30 min, among them one of the conditions corresponds to an unstimulated reference samples.
This is a classic example where one would choose mixed models, where patients would be treated as a random effect, over the traditional models with all effects fixed. Like this, one can account for the within patient variability, seen in the MDS plot, and gain more power in detecting differences between conditions of interest. 

We use the `r CRANpkg("lme4")` package to fit the mixed models and the `r CRANpkg("multcomp")` package for hypothesis testing.
In all the differential analysis in here, we want to test for differences between the reference (`Ref`) and BCR/FcR-XL treatment (`BCRXL`). The fixed model formula is very simple: `~ condition`, where `condition` is a column from the metadata object `md` which indicates the treatment group. The corresponding full model design matrix consists of the intercept and a column indicating which samples were treated with BCR/FcR-XL. 
In presence of batches, one can include them in the model by using a formula `~ condition + batch`, or if there is a potential they may affect the treatment a formula with interactions `~ condition * batch`.

For testing, we use the general linear hypotheses function `glht`, which allows testing more complicated hypothesis than the one corresponding to a single regression coefficient.  
The `linfct` parameter specifies the linear hypotheses to be tested, it should be a matrix where each row corresponds to one comparison (contrast) of interest, and the number of columns must be the same as in the design matrix. 
In our analysis, the contrast matrix indicates that the regression coefficient corresponding to `conditionBCRXL` is tested to be equal to zero, meaning, we test the null hypothesis that there is no effect of the BCR/FcR-XL treatment. 
The hypothesis is rejected, when there is a sufficient evidence for the differences between the two conditions, i.e., the differences are not due to the experimental variability which one can expect between different samples from the same treatment group.
The result of the test is reported with a p-value, which is a probability of observing as strong, or even stronger, difference between the two conditions as if it was observed under the situation described by the null hypothesis.

In our analysis, testing is performed on each cluster or marker separately. Thus, to account for the multiple testing correction, we apply the Benjamini & Hochberg adjustment. We use FDR of 5% as a significance cutoff.


```{r diff_freqs_define_model}
library(lme4)
library(multcomp)

## Model formula without random effects
model.matrix( ~ condition, data = md)

## Create contrasts
contrast_names <- c("BCRXLvsRef")
k1 <- c(0, 1)
K <- matrix(k1, nrow = 1, byrow = TRUE)
rownames(K) <- contrast_names
K

```

```{r diff_FDR_cutoff}
FDR_cutoff <- 0.05
```



## DA of marker expression stratified by cell population

In the code chunk below, we calculate the median expression of the 14 signaling markers in each cluster and sample. This values will be used as a dependent variable `y` in the linear mixed model (LMM), for which we assume that the median marker expression follows a Gaussian distribution.
One drawback of summarizing the protein marker intensity with median is that all the other characteristics of the distribution, such as bimodality, skewness and variance, are ignored. 
On the other hand, it results in a simple, easy to interpret approach, which in many cases is sufficient to detect interesting differences between conditions. 
Other issue that arises when using a summary statistic of a distribution is its uncertainty, which increases as the number of cells used to calculate it decreases. 
In the linear model, this problem could be partially handled by assigning weights, which are proportional to the number of cells in a given cluster and sample. However, since each cluster is tested separately, these weights do not account for the differences in size between clusters.


There might be instances of small cell populations for which no cells are observed in some samples or the number of cells is very low. 
This can be a problem, as it introduces NAs because the median expression can not be calculated or the median expression is calculated based on very few cells, which leads to higher uncertainty.
We decided to remove clusters which have too low counts in some samples and cases where marker expression is equal to in all the samples, as this leads to an error during model fitting. 


```{r diff_expr2_median_expression}
expr_median_sample_cluster <- aggregate(expr[, functional_markers], by = list(sample_id = sample_ids, cluster = cell_clustering3), FUN = median, drop = FALSE)
expr_median_sample_cluster_melt <- melt(expr_median_sample_cluster, id.vars = c("sample_id", "cluster"), value.name = "median_expression", variable.name = "antigen")
expr_median_sample_cluster <- dcast(expr_median_sample_cluster_melt, cluster + antigen ~ sample_id, value.var = "median_expression")
rownames(expr_median_sample_cluster) <- paste0(expr_median_sample_cluster$cluster, "_", expr_median_sample_cluster$antigen)

# clusters_keep <- names(which((rowSums(freq < 5) == 0)))
# expr_median_sample_cluster <- expr_median_sample_cluster[expr_median_sample_cluster$cluster %in% clusters_keep, ]

## Eliminate cases with zero expression in all samples
expr_median_sample_cluster <- expr_median_sample_cluster[rowSums(expr_median_sample_cluster[, md$sample_id]) > 0, ]
```

It is very useful to plot the median expression of all the markers in each cluster for each sample colored by condition to get a rough image of how strong the differences might be. Our preferred visualization consists of a boxplot with the exact values plotted on top as jittered points. Box plots are perfect representation only of the one modal distributions, as they tend to mask the multimodality. Thus, to be sure that none of the distribution characteristics escape our eyes it is always good to plot along the original values boxplot features were calculated with.


```{r diff_expr2_plot_median_expr, fig.cap = "Median expression of 14 signaling markers in the identified PBMC cell populations."}
ggdf <- expr_median_sample_cluster_melt
## Add info about samples
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- factor(md$condition[mm])

ggplot(ggdf) +
  geom_boxplot(aes(x = antigen, y = median_expression, color = condition, fill = condition), position = position_dodge(), alpha = 0.5, outlier.color = NA) +
  geom_point(aes(x = antigen, y = median_expression, color = condition), alpha = 0.8, position = position_jitterdodge(), size = 0.5) +
  facet_wrap(~ cluster, scales = "free_y") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  scale_color_manual(values = color_conditions) +
  scale_fill_manual(values = color_conditions)

```

We have created a wrapper function `differential_expression_wrapper` that performs the differential analysis of marker expression. The user has to specify a data frame `expr_median` with marker expression, where each column corresponds to a sample and each row to a given cluster and marker. One can choose between fitting a regular linear model `model = "lm"` or a linear mixed model `model = "lmer"`. 
The `formula` parameter must be adjusted adequately to the model. 
The wrapper function returns the adjusted p-values from each of the specified contrasts `K` for each cluster-marker. 


```{r diff_differential_expression_wrapper}
differential_expression_wrapper <- function(expr_median, md, model = "lmer", formula, K){
  ### Fit LMM or LM for each marker separately
  fit_gaussian <- lapply(1:nrow(expr_median), function(i){
    data_tmp <- data.frame(y = as.numeric(expr_median[i, md$sample_id]), md)
    switch(model, 
      lmer = {
        fit_tmp <- lmer(formula, data = data_tmp)
      },
      lm = {
        fit_tmp <- lm(formula, data = data_tmp)
      })
    ## Fit contrasts one by one
    out <- apply(K, 1, function(k){
      contr_tmp <- glht(fit_tmp, linfct = matrix(k, 1))
      summ_tmp <- summary(contr_tmp)
      pval <- summ_tmp$test$pvalues
      return(pval)
    })
    return(out)
  })
  pvals <- do.call(rbind, fit_gaussian)
  colnames(pvals) <- paste0("pval_", contrast_names)
  rownames(pvals) <- rownames(expr_median)
  ## Adjust the p-values
  adjp <- apply(pvals, 2, p.adjust, method = "BH")
  colnames(adjp) <- paste0("adjp_", contrast_names)
  return(adjp)
}

```


To present how accounting for the within patient variability with the mixed model increases the power, we also fit a regular linear model. 
The linear mixed model has a random intercept which corresponds to the patient ID.


```{r diff_expr2_formula}
formula_lm <- y ~ condition
formula_lmer <- y ~ condition + (1|patient_id)
```

By accounting for the patient effect, we are able to detect almost twice as much cases of differential signaling as with the regular linear model.  

```{r diff_expr2_fit_model}
adjp <- differential_expression_wrapper(expr_median = expr_median_sample_cluster, md = md, model = "lm", formula = formula_lm, K = K)
apply(adjp < 0.05, 2, table)

adjp <- differential_expression_wrapper(expr_median = expr_median_sample_cluster, md = md, model = "lmer", formula = formula_lmer, K = K)
apply(adjp < 0.05, 2, table)

```

We can report the significant results with a heatmap.
Instead of the absolute expression we use the normalized expression, which highlights more the direction of marker changes.  

We created two wrapper functions: `normalization_wrapper` performs the normalization of submitted expression `expr` to mean 0 and standard deviation 1, and `plot_differential_heatmap_wrapper` generates a heatmap of submitted expression `expr_norm`, where samples are grouped by `condition`, which is indicated with a color bar on top of the plot. 
Additionally, labels of clusters and markers contain in the parenthesis the adjusted p-values.

```{r normalization_wrapper}
normalization_wrapper <- function(expr, th = 2.5){
  expr_norm <- apply(expr, 1, function(x){ 
    sdx <- sd(x, na.rm = TRUE)
    if(sdx == 0){
      x <- (x - mean(x, na.rm = TRUE))
    }else{ 
      x <- (x - mean(x, na.rm = TRUE)) / sdx
    }
    x[x > th] <- th
    x[x < -th] <- -th
    return(x)
  })
  expr_norm <- t(expr_norm)
}

```


```{r diff_plot_differential_heatmap_wrapper}
plot_differential_heatmap_wrapper <- function(expr_norm, sign_adjp, condition, color_conditions, th = 2.5){
  ## Order samples by condition
  oo <- order(condition)
  condition <- condition[oo]
  expr_norm <- expr_norm[, oo, drop = FALSE]
  ## Create the row labels with adj p-values and other objects for pheatmap
  labels_row <- paste0(rownames(expr_norm), " (", sprintf( "%.02e", sign_adjp), ")")
  labels_col <- colnames(expr_norm)
  annotation_col <- data.frame(condition = factor(condition))
  rownames(annotation_col) <- colnames(expr_norm)
  annotation_colors <- list(condition = color_conditions)
  color <- colorRampPalette(c("#87CEFA", "#56B4E9", "#56B4E9", "#0072B2", "#000000", "#D55E00", "#E69F00", "#E69F00", "#FFD700"))(100)
  breaks = seq(from = -th, to = th, length.out = 101)
  legend_breaks = seq(from = -round(th), to = round(th), by = 1)
  gaps_col <- as.numeric(table(annotation_col$condition))
  
  pheatmap(expr_norm, color = color, breaks = breaks, legend_breaks = legend_breaks, cluster_cols = FALSE, cluster_rows = FALSE, labels_col = labels_col, labels_row = labels_row, gaps_col = gaps_col, annotation_col = annotation_col, annotation_colors = annotation_colors)
}
```

Additionally, we order the cluster-marker instances by their significance and group them by cluster.

```{r diff_expr2_plot_heatmap_with_significant_markers, fig.cap="Normalized expression of signaling markers that are significantly differentially expressed between BCR/FcR-XL stimulated and unstimulated condition."}

## Keep the significant markers, sort them by significance and group by cluster
sign_clusters_markers <- names(which(adjp[, "adjp_BCRXLvsRef"] < FDR_cutoff))
oo <- order(expr_median_sample_cluster[sign_clusters_markers, "cluster"], adjp[sign_clusters_markers, "adjp_BCRXLvsRef"])
sign_clusters_markers <- sign_clusters_markers[oo]
## Get the significant adjusted p-values
sign_adjp <- adjp[sign_clusters_markers , "adjp_BCRXLvsRef"]
## Normalize expression to mean = 0 and sd = 1
expr_median_sample_cluster_norm <- normalization_wrapper(expr_median_sample_cluster[sign_clusters_markers, md$sample_id])

plot_differential_heatmap_wrapper(expr_norm = expr_median_sample_cluster_norm, sign_adjp = sign_adjp, condition = md[colnames(expr_median_sample_cluster_norm), "condition"], color_conditions = color_conditions)

```




## DA of the overall marker expression

This analysis are conducted in the analogous manner as those described above with the difference that the median marker expression is measured from all the cells in a given sample, see the `expr_median_sample` object.


```{r diff_expr1_plot_median_expr, fig.cap="Median expression of 14 signaling markers calculated from all the cells in a given sample."}
ggdf <- melt(data.frame(antigen = functional_markers, expr_median_sample[functional_markers, ]), id.vars = "antigen", value.name = "median_expression", variable.name = "sample_id")
## Add condition info
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- factor(md$condition[mm])

ggplot(ggdf) +
  geom_boxplot(aes(x = condition, y = median_expression, color = condition, fill = condition), position = position_dodge(), alpha = 0.5, outlier.color = NA) +
  geom_point(aes(x = condition, y = median_expression, color = condition), alpha = 0.8, position = position_jitterdodge()) +
  facet_wrap(~ antigen, scales = "free", nrow = 3) +
  theme_bw() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  scale_color_manual(values = color_conditions) +
  scale_fill_manual(values = color_conditions)

```

Similarly as in the analysis above, we identify more markers being differentially expressed with the LMM which accounts for the within patient variability as compared to the regular LM.

```{r diff_expr1_fit_model}
## Fit a linear model 
adjp <- differential_expression_wrapper(expr_median = expr_median_sample[functional_markers, ], md = md, model = "lm", formula = formula_lm, K = K)
apply(adjp < 0.05, 2, table)
## Fit a linear mixed model with patient ID as a random effect
adjp <- differential_expression_wrapper(expr_median = expr_median_sample[functional_markers, ], md = md, model = "lmer", formula = formula_lmer, K = K)
apply(adjp < 0.05, 2, table)

```

As before, we plot a heatmap with the significant markers sorted by their significance.

```{r diff_expr1_plot_heatmap_with_significant_markers, fig.cap="Normalized expression for signaling markers that are significantly differentially expressed between BCR/FcR-XL stimulated and unstimulated condition."}
## Keep the significant markers and sort them by significance
sign_markers <- names(which(sort(adjp[, "adjp_BCRXLvsRef"]) < FDR_cutoff))
## Get the adjusted p-values
sign_adjp <- adjp[sign_markers , "adjp_BCRXLvsRef"]
## Normalize expression to mean = 0 and sd = 1
expr_median_sample_norm <- normalization_wrapper(expr_median_sample[sign_markers, ])

plot_differential_heatmap_wrapper(expr_norm = expr_median_sample_norm, sign_adjp = sign_adjp, condition = md[colnames(expr_median_sample_norm), "condition"], color_conditions = color_conditions)

```



## DA of cell population abundance


In this workflow, by differential analysis of cell abundance, we refer to analysis that compares proportions of cell types present in different conditions and aims at identifying those populations that are present at different ratios across conditions.

In the code chunk below, we calculate two tables: one which contains counts of cells that originate from a given sample and were assigned to a given cell population, and one with proportions of cell types present in each sample. 
The proportions are used only for plotting, as the actual differential analysis take as input the count table, see below.


```{r diff_freqs}
counts_table <- table(cell_clustering3, sample_ids)
props_table <- t(t(counts_table) / colSums(counts_table)) * 100

counts <- as.data.frame.matrix(counts_table)
props <- as.data.frame.matrix(props_table)
```


For each sample, we plot its PBMC cell type composition represented with a colorful bar, where the size of a given stripe reflects proportion of the corresponding cell type in a given sample.


```{r diff_freqs_plot_props_barplot, fig.cap="Relative abundance of PBMC populations in each sample represented with a barplot."}
ggdf <- melt(data.frame(cluster = rownames(props), props), id.vars = "cluster", value.name = "proportion", variable.name = "sample_id")
## Add condition info
mm <- match(ggdf$sample_id, md$sample_id)
ggdf$condition <- factor(md$condition[mm])

ggplot(ggdf, aes(x = sample_id, y = proportion, fill = cluster)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ condition, scales = "free_x") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_manual(values = color_clusters) 

```

It may be quite hard to see the differences in the cluster abundances in the plot above, especially for clusters with very low frequency for which stripes in the barplot are very tiny. 
We find that the plot that was suggested for visualizing marker expression may be very useful. The y-axes are scaled to the range of data plotted in a given facet visualizing better the differences in frequency of smaller clusters.

```{r diff_freqs_plot_props_boxplot, fig.cap="Relative abundance of PBMC populations in each sample plotted using boxplots."}
ggplot(ggdf) +
  geom_boxplot(aes(x = condition, y = proportion, color = condition, fill = condition), position = position_dodge(), alpha = 0.5, outlier.color = NA) +
  geom_point(aes(x = condition, y = proportion, color = condition), alpha = 0.8, position = position_jitterdodge()) +
  facet_wrap(~ cluster, scales = "free", nrow = 2) +
  theme_bw() +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  scale_color_manual(values = color_conditions) +
  scale_fill_manual(values = color_conditions)

```

As our goal is to compare proportions, one could take those values, transform them with logit, to map the values between 0 and 1 to the real line, and use them as a dependent variable in a linear model. 
However, this approach does not take into account the uncertainty of proportion estimates, which is higher when ratios are calculated for samples with lower total cell counts. 
A distribution that naturally accounts for such uncertainty is the binomial distribution used in the logistic regression, which takes as dependent input the counts.
Nevertheless, as in the genomic data analysis, the pure logistic regression is not able to capture the overdispersion which we have also observed in the CyTOF data. 
A more suitable model would be based on the beta-binomial distribution, or similar results can be achieved by modeling the extra variance of ratios as random effects for each individual sample in the generalized linear mixed model (GLMM) [@Jia2014, @Zhao2013].
Thus, we conduct the differential abundance analysis using mixed models (MM) but it is not due to the fact that the experiment is paired. Even if it was not paired, we would use MM because they allow to model the count variance accurately. It is important to note, that now the random effect is defined by the sample ID and not as before by patient ID.

```{r diff_formula_glmer_binomial}
formula_glmer_binomial <- y/total ~ condition + (1|sample_id)

```

The wrapper function for differential abundance analysis takes as input a data frame with counts of cells in each population (rows) and sample (columns) and performs the differential analysis specified with contrast `K` for each population separately and returns a table with adjusted p-values.

```{r diff_differential_abundance_wrapper}
differential_abundance_wrapper <- function(counts, md, formula, K){
  ## Fit the GLMM for each cluster separately
  ntot <- colSums(counts)
  fit_binomial <- lapply(1:nrow(counts), function(i){
    data_tmp <- data.frame(y = as.numeric(counts[i, md$sample_id]), total = ntot[md$sample_id], md)
    fit_tmp <- glmer(formula, weights = total, family = binomial, data = data_tmp)
    ## Fit contrasts one by one
    out <- apply(K, 1, function(k){
      contr_tmp <- glht(fit_tmp, linfct = matrix(k, 1))
      summ_tmp <- summary(contr_tmp)
      pval <- summ_tmp$test$pvalues
      return(pval)
    })
    return(out)
  })
  pvals <- do.call(rbind, fit_binomial)
  colnames(pvals) <- paste0("pval_", contrast_names)
  rownames(pvals) <- rownames(counts)
  ## Adjust the p-values
  adjp <- apply(pvals, 2, p.adjust, method = "BH")
  colnames(adjp) <- paste0("adjp_", contrast_names)
  return(adjp)
}
```


```{r diff_freqs_fit_model}
adjp <- differential_abundance_wrapper(counts, md = md, formula = formula_glmer_binomial, K = K)
apply(adjp < 0.05, 2, table)

```

Again we use a heatmap to report the significantly differential cell populations.
Proportions are first scaled with the arcsine-square-root transformation, which is an alternative to logit, that does not return NAs when ratios are equal to zero or one. Then, the normalization to the mean zero and standard deviation of one is applied to each population to enhance the differences between compared conditions.


```{r diff_freqs_asin_sqrt_transformation}
## Apply the arcsine-square-root transformation
asin_table <- asin(sqrt((t(t(counts_table) / colSums(counts_table)))))
asin <- as.data.frame.matrix(asin_table)
## Keep significant clusters and sort them by significance
sign_clusters <- names(which(sort(adjp[, "adjp_BCRXLvsRef"]) < FDR_cutoff))
## Get the adjusted p-values
sign_adjp <- adjp[sign_clusters , "adjp_BCRXLvsRef"]
## Keep samples for condition A and normalize to mean = 0 and sd = 1
asin_norm <- normalization_wrapper(asin[sign_clusters, ])

```



```{r diff_freqs_plot_heatmap_with_significant_clusters, fig.cap="Normalized proportions of PBMC cell populations that are significantly differentially abundant between BCR/FcR-XL stimulated and unstimulated condition."}

plot_differential_heatmap_wrapper(expr_norm = asin_norm, sign_adjp = sign_adjp, condition = md[colnames(asin_norm), "condition"], color_conditions = color_conditions)

```



All the wrapper functions were created and adjusted for the needs of this workflow. For the real data analysis, the user should modify them according to its purpose.






# Session Info


```{r sessionInfo}
sessionInfo()
```










<!-- # Author contributions -->

<!-- # Competing interests -->

<!-- # Grant information -->

<!-- # Acknowledgments -->




# References

